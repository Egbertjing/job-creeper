{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as PD\n",
    "import numpy as NP\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver  \n",
    "from selenium.common.exceptions import TimeoutException \n",
    "# import ActionChains mouse operation  \n",
    "from selenium.webdriver.common.action_chains import ActionChains \n",
    "\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html(number):\n",
    "    try:\n",
    "        chrome_options=Options()\n",
    "        chrome_options.add_argument('--headless')\n",
    "        driver= webdriver.Chrome(chrome_options=chrome_options)  \n",
    "        driver.get('https://t.me/stablegram/' + str(number))\n",
    "        # temp_height=0\n",
    " \n",
    "        # while True:\n",
    "        #     #循环将滚动条下拉\n",
    "        #     driver.execute_script(\"window.scrollBy(0,100000)\")\n",
    "        #     #sleep一下让滚动条反应一下\n",
    "        #     time.sleep(5)\n",
    "        #     #获取当前滚动条距离顶部的距离\n",
    "        #     check_height = driver.execute_script(\"return document.documentElement.scrollTop || window.pageYOffset || document.body.scrollTop;\")\n",
    "        #     #如果两者相等说明到底了\n",
    "        #     if check_height==temp_height:\n",
    "        #         break\n",
    "        #     temp_height=check_height\n",
    "        #     print('*****Processing temp_height = {temp_height}*****'.format(temp_height=temp_height))\n",
    "        # print('done')\n",
    "        page = driver.page_source\n",
    "        source = page.encode(\"utf8\")\n",
    "        soup_list = BeautifulSoup(source, 'lxml')\n",
    "        return soup_list\n",
    "    except:\n",
    "        return \"ERROR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(number):\n",
    "    try:\n",
    "        response  = requests.get('https://t.me/stablegram/' + str(number))\n",
    "        response.encoding=\"utf-8\"\n",
    "        source = response.text\n",
    "        content = BeautifulSoup(source, 'lxml')\n",
    "        return content#.find_all('meta')[5]\n",
    "    except:\n",
    "        return \"ERROR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = get_url(430)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Remote\n"
     ]
    }
   ],
   "source": [
    "source_spilt = source.find_all('meta')[5]['content'].split(\"🌎\")[1].split(\"\\n\")[0]\n",
    "print(source_spilt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing job id 73\n",
      "Processing job id 74\n",
      "Processing job id 75\n",
      "Processing job id 76\n",
      "Processing job id 77\n",
      "Processing job id 78\n",
      "Processing job id 79\n",
      "Processing job id 80\n",
      "Processing job id 81\n",
      "Processing job id 82\n",
      "Processing job id 83\n",
      "Processing job id 84\n",
      "Processing job id 85\n",
      "Processing job id 86\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [51], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m job_title_list[index] \u001b[39m=\u001b[39m source\u001b[39m.\u001b[39mfind_all(\u001b[39m'\u001b[39m\u001b[39mmeta\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m5\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     17\u001b[0m type_list[index] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mNot Provided\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> 18\u001b[0m location_list[index] \u001b[39m=\u001b[39m source\u001b[39m.\u001b[39;49mfind_all(\u001b[39m'\u001b[39;49m\u001b[39mmeta\u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m5\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49msplit(\u001b[39m\"\u001b[39;49m\u001b[39m🌎\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     19\u001b[0m description_list[index] \u001b[39m=\u001b[39m source\u001b[39m.\u001b[39mfind_all(\u001b[39m'\u001b[39m\u001b[39mmeta\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m5\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     20\u001b[0m working_type_list[index] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mNot Provided\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "number_list = []\n",
    "description_list = {}\n",
    "job_title_list = {}\n",
    "type_list = {}\n",
    "location_list = {}\n",
    "working_type_list = {}\n",
    "contact_list = {}\n",
    "achievements_list = {}\n",
    "base_salary_list = {}\n",
    "equity_list = {}\n",
    "\n",
    "for index in range(73,432):\n",
    "    print('Processing job id '+ str(index))\n",
    "    source = get_url(index)\n",
    "    number_list.append(index)\n",
    "    job_title_list[index] = source.find_all('meta')[5]['content'].split(\"\\n\")[0]\n",
    "    type_list[index] = 'Not Provided'\n",
    "    location_list[index] = source.find_all('meta')[5]['content'].split(\"🌎\")[1].split(\"\\n\")[0]\n",
    "    description_list[index] = source.find_all('meta')[5]['content']\n",
    "    working_type_list[index] = 'Not Provided'\n",
    "    contact_list[index] = 'Not Provided'\n",
    "    achievements_list[index] = 'Null'\n",
    "    base_salary_list[index] = 'Not Provided'\n",
    "    equity_list[index] = 'Not Provided'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all the results\n",
    "count = 0\n",
    "total_columns = ['Job title', 'Type of position', 'Job Location', 'Job description', 'Working type', 'Contact', 'Achievements', 'Base salary', 'Equity']\n",
    "total_values = [[] for _ in total_columns]\n",
    "\n",
    "for single_job in number_list:\n",
    "    count += 1\n",
    "    print(\"*****Processing job {job}*****\".format(job=job_title_list[single_job]))\n",
    "    print(\"Type of position: \" + type_list[single_job])\n",
    "    print(\"Job location: \" + location_list[single_job])\n",
    "    print(\"Job description: \" + description_list[single_job])\n",
    "    print(\"Working type: \" + working_type_list[single_job])\n",
    "    print(\"Contract: \" + contact_list[single_job])\n",
    "    print(\"Achievements: \" + achievements_list[single_job])\n",
    "    print(\"Base salary: \" + base_salary_list[single_job])\n",
    "    print(\"Equity: \" + equity_list[single_job])\n",
    "    \n",
    "    single_values = [\n",
    "        single_job,\n",
    "        type_list[single_job],\n",
    "        location_list[single_job],\n",
    "        description_list[single_job],\n",
    "        working_type_list[single_job],\n",
    "        contact_list[single_job],\n",
    "        achievements_list[single_job],\n",
    "        base_salary_list[single_job],\n",
    "        equity_list[single_job]\n",
    "    ]\n",
    "    for value_index in range(len(total_columns)):\n",
    "        total_values[value_index].append(single_values[value_index])\n",
    "final_result = {}\n",
    "for column_index in range(len(total_columns)):\n",
    "    final_result.update({\n",
    "        total_columns[column_index]: total_values[column_index]\n",
    "    })\n",
    "final_result = PD.DataFrame(final_result)\n",
    "\n",
    "print(\"*****Total count {count}*****\".format(count=count))\n",
    "file_name = \"jobs.csv\"\n",
    "print(\"*****Save the result to file {file}*****\".format(file=file_name))\n",
    "final_result.to_csv(file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a10c7ff833cd258db03f4dddaa328fa7efa8249840dd32d59773f308d465ac00"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
